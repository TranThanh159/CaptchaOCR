{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1agkzI7fbYr4iJdFiIOIa5B3hk3_Yepot?usp=sharing"
      ],
      "metadata": {
        "id": "0FsVu1QMP1fa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pze3IRe2Ifo9"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore UserWarnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Ignore TensorFlow warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)"
      ],
      "metadata": {
        "id": "2As7ap3BarvT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "XYcZIsxNZO8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade gdown\n",
        "!gdown https://drive.google.com/uc?id=1HupS43P60W1vzBxEvNMmKJubum9QqY_r\n",
        "!unzip -q /content/data_v2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "590ttAeVYLiJ",
        "outputId": "f2455647-0b8d-40d4-b7c4-19627c164555"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1HupS43P60W1vzBxEvNMmKJubum9QqY_r\n",
            "From (redirected): https://drive.google.com/uc?id=1HupS43P60W1vzBxEvNMmKJubum9QqY_r&confirm=t&uuid=84fad731-ba15-408b-b87b-c3dbc9cdab4a\n",
            "To: /content/data_v2.zip\n",
            "100% 370M/370M [00:04<00:00, 78.1MB/s]\n",
            "unzip:  cannot find or open content/data_v2.zip, content/data_v2.zip.zip or content/data_v2.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQuCEsSI4zo",
        "outputId": "891ab6b8-183e-43f0-cfc8-c4eb5d17b0ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/resnet50v2 TL/fingerprint.pb',\n",
              " '/content/resnet50v2 TL/keras_metadata.pb',\n",
              " '/content/resnet50v2 TL/saved_model.pb',\n",
              " '/content/resnet50v2 TL/variables/variables.data-00000-of-00001',\n",
              " '/content/resnet50v2 TL/variables/variables.index']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import gdown\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1-CKKgpis2PShA3wQL1F9Rkq5i-Yv6hCm?usp=drive_link\", quiet=True)\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1QiTPba9c916OZLXHU9c3F_VN_TQ-PEYm?usp=sharing\", quiet=True)\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1Eq9vKx2fNiG1zSA6CHRS4cSNJrvu5soI?usp=sharing\",quiet=True)\n",
        "gdown.download_folder(\"https://drive.google.com/drive/u/0/folders/1Ls1pBGEqN0cB3Hz5RNsSAlDQuF707CUK\",quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "I2RpygN8WBp5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INIT VALIDATOR"
      ],
      "metadata": {
        "id": "hRmVN62BXH9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the data directory\n",
        "data_dir = Path(\"./data_v2/\")#(\"./captcha_images_v2/\")\n",
        "\n",
        "# Get list of all the images\n",
        "images = sorted(list(map(str, list(data_dir.glob(\"*.jpg\")))))\n",
        "labels = [img.split(os.path.sep)[-1].split(\".jpg\")[0] for img in images]\n",
        "characters = set(char for label in labels for char in label)#Set trong Python là tập hợp các phần tử duy nhất, không có thứ tự\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "print(\"Number of images found: \", len(images))\n",
        "print(\"Number of labels found: \", len(labels))\n",
        "print(\"Number of unique characters: \", len(characters))\n",
        "print(\"Characters present: \", characters)\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 512\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "\n",
        "# Maximum length of any captcha in the dataset\n",
        "max_length = max([len(label) for label in labels])\n",
        "X_train,X_val_test,y_train,y_val_test=train_test_split(images,labels,test_size=0.2,random_state=2023)\n",
        "X_val,X_test,y_val,y_test=train_test_split(X_val_test,y_val_test,test_size=0.5,random_state=2023)\n",
        "\n",
        "x_train=np.array(X_train)\n",
        "x_val=np.array(X_val)\n",
        "x_test=np.array(X_test)\n",
        "\n",
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)\n",
        "y_test=np.array(y_test)\n",
        "# Mapping characters to integers\n",
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=list(characters), mask_token=None\n",
        ")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def encode_single_sample(img_path, label):\n",
        "    # 1. Read image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    #print(img)\n",
        "    # 2. Decode and convert to grayscale\n",
        "    img = tf.io.decode_png(img, channels=3)#channels=1 để chuyển sang thang độ xám, để 3 nếu muốn nahr màu\n",
        "\n",
        "\n",
        "    #print(img)\n",
        "    # 3. Convert to float32 in [0, 1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    #print(img)\n",
        "    # 4. Resize to the desired size\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    #print(img.shape)\n",
        "    # 5. Transpose the image because we want the time\n",
        "    # dimension to correspond to the width of the image.\n",
        "    img = tf.transpose(img, perm=[1, 0, 2])# chuyển vị matrix hàng thành cột và cột thành hàng\n",
        "    #print(img.shape)\n",
        "    # 6. Map the characters in label to numbers\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "    # 7. Return a dict as our model is expecting two inputs\n",
        "    return {\"image\": img, \"label\": label}\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (\n",
        "    train_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = (\n",
        "    test_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ho-ilyGWEXd",
        "outputId": "2db33967-afae-4ce9-cedb-502fe7299587"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found:  113062\n",
            "Number of labels found:  113062\n",
            "Number of unique characters:  60\n",
            "Characters present:  ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getACC(model,dataset,_y_true):\n",
        "  pred = model.predict(dataset,verbose = 0)\n",
        "  pred_texts = decode_batch_predictions(pred)\n",
        "  y_true = _y_true\n",
        "  correct_char = 0\n",
        "  total_char = 0\n",
        "  correct = 0\n",
        "  #xét từng cặp true,pred\n",
        "  # nếu true=pred thì số nhãn đoán đúng +1\n",
        "  # với mỗi kí tự trong true ss với kí tự trong pred ở vị trí tương ứng, nếu bằng số kí tự đúng +1\n",
        "  for i in range(len(y_true)):\n",
        "      pr = pred_texts[i]\n",
        "      tr = y_true[i]\n",
        "      total_char += len(tr)\n",
        "      for j in range(min(len(tr), len(pr))):\n",
        "          if tr[j] == pr[j]:\n",
        "              correct_char += 1\n",
        "\n",
        "      if pr == tr :\n",
        "          correct += 1\n",
        "\n",
        "  print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))#nếu muốn tính % sai hãy dùng Edit distance\n",
        "  print('Correct words predicted      : %.2f%%' %(correct*100/len(y_true)))"
      ],
      "metadata": {
        "id": "1iK6Z2qKZ1AG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waCfwniZOow8"
      },
      "source": [
        "##LOAD TRAINED MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initial(model):\n",
        "  image = cv2.imread('/content/model_ALexNet/Capture.PNG')\n",
        "  tensor=image[:, :, :3]/255\n",
        "  tensor= tf.image.transpose(tensor)\n",
        "  tensor = tf.image.resize(tensor, [200, 50])\n",
        "  image =tf.image.resize(tensor, [200, 50])\n",
        "  _image= tf.reshape(image, (1, 200, 50, 3))\n",
        "  model.predict(_image, verbose=0)\n",
        "def load_model_CNN():\n",
        "  model=tf.keras.saving.load_model(\"/content/CNN/ocr_model\")\n",
        "  initial(model)\n",
        "  return model\n",
        "\n",
        "def load_model_Res():\n",
        "  model= tf.keras.saving.load_model(\"/content/resnet50v2.keras\")\n",
        "  initial(model)\n",
        "  return model\n",
        "def load_model_Res_TL():\n",
        "  model= tf.keras.saving.load_model(\"/content/resnet50v2 TL\")\n",
        "  initial(model)\n",
        "  return model\n",
        "def load_model_Alex():\n",
        "  model= tf.keras.saving.load_model(\"/content/model_ALexNet\")\n",
        "  initial(model)\n",
        "  return model\n",
        "CNN_model_pred=load_model_CNN()\n",
        "RES_model_pred=load_model_Res()\n",
        "RES_TL_model_pred=load_model_Res_TL()\n",
        "ALEX_mode_pred=load_model_Alex()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo8eNPXIVsWB",
        "outputId": "7f3b13fd-b040-4985-93ca-00ff1f1b738c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:5 out of the last 119 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e6bd9768310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kccYE2lkN20y"
      },
      "source": [
        "# get Result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Val Dataset"
      ],
      "metadata": {
        "id": "EZmDSqllaIzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get Accuracy\n",
        "#CNN\n",
        "print(\"CNN\")\n",
        "getACC(CNN_model_pred,validation_dataset,y_val)\n",
        "\n",
        "#Alex\n",
        "print(\"Alex\")\n",
        "getACC(ALEX_mode_pred,validation_dataset,y_val)\n",
        "\n",
        "#ResNET Feature Extracter\n",
        "print(\"RES FE\")\n",
        "getACC(RES_model_pred,validation_dataset,y_val)\n",
        "\n",
        "#ResNET TransferLearning\n",
        "print(\"RES TL\")\n",
        "getACC(RES_TL_model_pred,validation_dataset,y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3kM2gwGaPAp",
        "outputId": "dad3beff-dd71-4a21-8f48-8f35f4fc833c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Test Dataset"
      ],
      "metadata": {
        "id": "j4yMpZc1brs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get Accuracy\n",
        "#CNN\n",
        "print(\"CNN\")\n",
        "getACC(CNN_model_pred,test_dataset,y_test)\n",
        "\n",
        "#Alex\n",
        "print(\"Alex\")\n",
        "getACC(ALEX_mode_pred,test_dataset,y_test)\n",
        "\n",
        "#ResNET Feature Extracter\n",
        "print(\"RES FE\")\n",
        "getACC(RES_model_pred,test_dataset,y_test)\n",
        "\n",
        "#ResNET TransferLearning\n",
        "print(\"RES TL\")\n",
        "getACC(RES_TL_model_pred,test_dataset,y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvAHCWC-bvS_",
        "outputId": "f287be64-947a-4b1e-d2a4-4bc0b54b123a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN\n",
            "Correct characters predicted : 89.36%\n",
            "Correct words predicted      : 69.41%\n",
            "Alex\n",
            "Correct characters predicted : 84.92%\n",
            "Correct words predicted      : 58.52%\n",
            "RES FE\n",
            "Correct characters predicted : 70.31%\n",
            "Correct words predicted      : 23.83%\n",
            "RES TL\n",
            "Correct characters predicted : 89.04%\n",
            "Correct words predicted      : 69.57%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}